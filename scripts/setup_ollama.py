#!/usr/bin/env python3
"""
Interactive setup script for Paper2Slides with Ollama.
Detects local models and generates a .env file.
"""

import os
import sys
import json
import urllib.request
from typing import List, Dict, Optional

OLLAMA_API_URL = "http://localhost:11434/api/tags"

def get_ollama_models() -> List[str]:
    """Fetch list of available models from local Ollama instance."""
    try:
        with urllib.request.urlopen(OLLAMA_API_URL) as response:
            if response.status != 200:
                print(f"Error: Ollama returned status code {response.status}")
                return []
            data = json.loads(response.read().decode())
            return [model['name'] for model in data.get('models', [])]
    except urllib.error.URLError:
        print("Error: Could not connect to Ollama at http://localhost:11434")
        print("Please ensure Ollama is running.")
        return []
    except Exception as e:
        print(f"Error fetching models: {e}")
        return []

def select_model(models: List[str], prompt: str, filter_keywords: List[str] = None, default: str = None) -> str:
    """Interactive model selection."""
    print(f"\n--- {prompt} ---")
    
    # Filter suggestions
    suggestions = []
    if filter_keywords:
        for m in models:
            if any(k in m for k in filter_keywords):
                suggestions.append(m)
    else:
        suggestions = models

    # If no suggestions found matching filter, show all
    display_list = suggestions if suggestions else models
    
    if not display_list:
        print("No local models found matching criteria.")
        manual = input(f"Please enter model name manually (default: {default}): ").strip()
        return manual if manual else default

    for i, m in enumerate(display_list):
        print(f"{i + 1}. {m}")
    
    print(f"0. Enter manually")
    
    while True:
        choice = input(f"Select a model (1-{len(display_list)}) [default: {display_list[0]}]: ").strip()
        
        if not choice:
            return display_list[0]
        
        if choice == '0':
            return input("Enter model name: ").strip()
            
        try:
            idx = int(choice) - 1
            if 0 <= idx < len(display_list):
                return display_list[idx]
        except ValueError:
            pass
        print("Invalid selection. Please try again.")

def main():
    print("=" * 60)
    print("Paper2Slides - Ollama Setup Assistant")
    print("=" * 60)
    
    print("Checking Ollama connection...")
    models = get_ollama_models()
    
    if not models:
        print("\nCould not detect any Ollama models.")
        print("Ensure 'ollama serve' is running and you have pulled models (e.g., 'ollama pull llama3').")
        sys.exit(1)
        
    print(f"Found {len(models)} models.")
    
    # 1. Select Main LLM
    llm_model = select_model(
        models, 
        "Select Main LLM (Chat/Reasoning)", 
        filter_keywords=["llama", "qwen", "mistral", "gemma"],
        default="llama3"
    )
    
    # 2. Select Vision Model
    vision_model = select_model(
        models, 
        "Select Vision Model (Image Analysis)", 
        filter_keywords=["llava", "vision", "moondream", "vl", "minicpm", "yi-vl", "qwen"],
        default="llava"
    )
    
    # 3. Select Embedding Model
    embed_model = select_model(
        models, 
        "Select Embedding Model (RAG)", 
        filter_keywords=["embed", "nomic", "mxbai"],
        default="nomic-embed-text"
    )
    
    # Ask for embedding dimension if known
    embed_dim = "768" # Default for nomic-embed-text
    if "mxbai" in embed_model:
        embed_dim = "1024"
    elif "large" in embed_model:
        embed_dim = "1024" # Guess
        
    print(f"\nSelected Embedding Dimension: {embed_dim} (Default for common models)")
    custom_dim = input(f"Press Enter to keep {embed_dim}, or type custom dimension: ").strip()
    if custom_dim:
        embed_dim = custom_dim

    # 4. Image Gen Config (Optional)
    print("\n--- Image Generation (Slides/Posters) ---")
    print("Ollama currently doesn't support high-quality image generation for slides.")
    print("You can skip this step or enter keys for OpenRouter/OpenAI.")
    setup_img_gen = input("Configure Image Generation API? (y/N): ").lower().startswith('y')
    
    img_gen_key = ""
    img_gen_url = ""
    
    if setup_img_gen:
        img_gen_key = input("Enter Image Gen API Key: ").strip()
        img_gen_url = input("Enter Image Gen Base URL (optional): ").strip()

    # Generate .env content
    env_content = f"""# Generated by scripts/setup_ollama.py

# Provider Selection
LLM_PROVIDER=ollama

# Model Configuration
LLM_MODEL={llm_model}
VISION_MODEL={vision_model}
EMBEDDING_MODEL={embed_model}
EMBEDDING_DIM={embed_dim}

# Connection Settings
RAG_LLM_BASE_URL=http://localhost:11434/v1
RAG_LLM_API_KEY=ollama

# Image Generation
IMAGE_GEN_API_KEY={img_gen_key}
IMAGE_GEN_BASE_URL={img_gen_url}
"""

    print("\n" + "="*30)
    print("Preview of .env file:")
    print("="*30)
    print(env_content)
    print("="*30)
    
    confirm = input("Write to .env file? This will overwrite existing config. (y/N): ").lower()
    
    if confirm == 'y':
        try:
            # Ensure paper2slides directory exists
            output_dir = "paper2slides"
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
                
            output_path = os.path.join(output_dir, ".env")
            
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(env_content)
            print(f"\nSuccess! .env file created at {output_path}")
            print("You can now run: python -m paper2slides --input ...")
        except Exception as e:
            print(f"Error writing file: {e}")
    else:
        print("Operation cancelled.")

if __name__ == "__main__":
    main()
